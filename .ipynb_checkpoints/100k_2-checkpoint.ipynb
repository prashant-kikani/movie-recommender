{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df =pd.read_csv('u.data', sep='\\t', names=names)\n",
    "df.head()\n",
    "\n",
    "\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print (str(n_users) + ' users')\n",
    "print (str(n_items) + ' items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 6.30%\n"
     ]
    }
   ],
   "source": [
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]\n",
    "ratings\n",
    "\n",
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print ('Sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[0, :].nonzero()[0], \n",
    "                                        size=10, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test\n",
    "\n",
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_similarity(ratings, kind='user'):\n",
    "    if kind == 'user':\n",
    "        sim = ratings.dot(ratings.T)\n",
    "    elif kind == 'item':\n",
    "        sim = ratings.T.dot(ratings)\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return sim / norms / norms.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.16711628,  0.03444883, ...,  0.15130324,\n",
       "         0.17658202,  0.39360764],\n",
       "       [ 0.16711628,  1.        ,  0.11264639, ...,  0.16183775,\n",
       "         0.17358328,  0.10646181],\n",
       "       [ 0.03444883,  0.11264639,  1.        , ...,  0.05612672,\n",
       "         0.13633643,  0.0116145 ],\n",
       "       ..., \n",
       "       [ 0.15130324,  0.16183775,  0.05612672, ...,  1.        ,\n",
       "         0.07530127,  0.09550774],\n",
       "       [ 0.17658202,  0.17358328,  0.13633643, ...,  0.07530127,\n",
       "         1.        ,  0.16639724],\n",
       "       [ 0.39360764,  0.10646181,  0.0116145 , ...,  0.09550774,\n",
       "         0.16639724,  1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%timeit slow_user_similarity(train)\n",
    "fast_similarity(train, kind='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.35632609  0.28927645  0.42862895]\n",
      " [ 0.35632609  1.          0.27373228  0.48775209]\n",
      " [ 0.28927645  0.27373228  1.          0.3137646 ]\n",
      " [ 0.42862895  0.48775209  0.3137646   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "user_similarity = fast_similarity(train, kind='user')\n",
    "item_similarity = fast_similarity(train, kind='item')\n",
    "print (item_similarity[:4, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_fast_simple(ratings, similarity, kind='user'):\n",
    "    if kind == 'user':\n",
    "        return similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif kind == 'item':\n",
    "        return ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 7.17976744284\n",
      "Item-based CF MSE: 9.88265640226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)\n",
    "\n",
    "item_prediction = predict_fast_simple(train, item_similarity, kind='item')\n",
    "user_prediction = predict_fast_simple(train, user_similarity, kind='user')\n",
    "\n",
    "print ('User-based CF MSE: ' + str(get_mse(user_prediction, test)))\n",
    "print ('Item-based CF MSE: ' + str(get_mse(item_prediction, test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_topk(ratings, similarity, kind='user', k=40):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    if kind == 'user':\n",
    "        for i in range(ratings.shape[0]):\n",
    "            top_k_users = [np.argsort(similarity[:,i])[:-k-1:-1]]\n",
    "            for j in range(ratings.shape[1]):\n",
    "                pred[i, j] = similarity[i, :][top_k_users].dot(ratings[:, j][top_k_users]) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[i, :][top_k_users]))\n",
    "    if kind == 'item':\n",
    "        for j in range(ratings.shape[1]):\n",
    "            top_k_items = [np.argsort(similarity[:,j])[:-k-1:-1]]\n",
    "            for i in range(ratings.shape[0]):\n",
    "                pred[i, j] = similarity[j, :][top_k_items].dot(ratings[i, :][top_k_items].T) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[j, :][top_k_items]))        \n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k User-based CF MSE: 3.95088018388\n"
     ]
    }
   ],
   "source": [
    "pred = predict_topk(train, user_similarity, kind='user', k=40)\n",
    "print ('Top-k User-based CF MSE: ' + str(get_mse(pred, test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.68155863,  1.94142385,  1.56382315, ...,  0.        ,\n",
       "         0.0731557 ,  0.08054584],\n",
       "       [ 2.15818073,  0.        ,  0.39255581, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.05784684,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 3.9032819 ,  0.        ,  0.55166725, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 2.24297809,  0.65743059,  0.09315032, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 2.80318421,  2.26269983,  1.42014806, ...,  0.        ,\n",
       "         0.07231748,  0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
